{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import *\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "num_bag_train = 2000\n",
    "bags_list_train = []\n",
    "labels_list_train = []\n",
    "for i in range(num_bag_train):\n",
    "    indices = random_state.randint(0, len(train_x), bag_length)\n",
    "    bags_list_train.append(train_x[indices])\n",
    "    labels_list_train.append(train_y[indices])\n",
    "train_bag_x = np.array(bags_list_train)\n",
    "train_bag_y = np.array(labels_list_train)\n",
    "np.save('train_x', train_bag_x)\n",
    "np.save('train_y', train_bag_y)\n",
    "print(train_bag_y.mean())\n",
    "# 测试集\n",
    "num_bag_test = 500\n",
    "bags_list_test = []\n",
    "labels_list_test = []\n",
    "for i in range(num_bag_test):\n",
    "    indices = random_state.randint(0, len(test_x), bag_length)\n",
    "    bags_list_test.append(test_x[indices])\n",
    "    labels_list_test.append(test_y[indices])\n",
    "test_bag_x = np.array(bags_list_test)\n",
    "test_bag_y = np.array(labels_list_test)\n",
    "np.save('test_x', test_bag_x)\n",
    "np.save('test_y', test_bag_y)\n",
    "print(test_bag_y.mean())\n",
    "\n",
    "def label_bags(label_array):\n",
    "    counts = np.bincount(label_array)\n",
    "    if counts[7] and counts[9]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def generate_data(target_number=9, num_bag_train=2000, num_bag_test=1000, bag_size=10, seed=1):\n",
    "    (train_images, train_labels), (test_images, test_labels) \\\n",
    "        = tf.keras.datasets.mnist.load_data()\n",
    "    train_images, train_labels = train_images[:, :,\n",
    "                                              :, np.newaxis] / 255.0, train_labels\n",
    "    test_images, test_labels = test_images[:, :,\n",
    "                                           :, np.newaxis] / 255.0, test_labels\n",
    "    random_state = np.random.RandomState(seed)\n",
    "    bags_list_train = []\n",
    "    labels_list_train = []\n",
    "    for i in range(num_bag_train):\n",
    "        indices = random_state.randint(0, 60000, bag_size)\n",
    "        labels_in_bag = train_labels[indices]\n",
    "        bags_list_train.append(train_images[indices])\n",
    "        labels_list_train.append(labels_in_bag)\n",
    "    bags_list_test = []\n",
    "    labels_list_test = []\n",
    "    for i in range(num_bag_test):\n",
    "        indices = random_state.randint(0, 10000, bag_size)\n",
    "        labels_in_bag = test_labels[indices]\n",
    "        bags_list_test.append(test_images[indices])\n",
    "        labels_list_test.append(labels_in_bag)\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extract_layer = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(28,28,1)),\n",
    "    tf.keras.layers.Conv2D(20, kernel_size=5, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(strides=2),\n",
    "    tf.keras.layers.Conv2D(50, kernel_size=5, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(500, activation='relu')\n",
    "])\n",
    "attention_layer = Attention(500,128,1)\n",
    "classifer_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "my_model = MIL_attention(feature_extract_layer, attention_layer, classifer_layer)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 1 is 5.743231773376465 sec\n",
      "Loss: 0.08956658840179443\n",
      "Accuracy: 0.976\n"
     ]
    }
   ],
   "source": [
    "train(train_data, my_model, 1, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer mil_attention is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = [my_model(i[0]) for i in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = [i[1] for i in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = [1 if i[0][0] > 0.5 else 0 for i in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.939"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(pred_label) == np.array(true)).sum()/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.9795852]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       " array([[9.9136995e-04],\n",
       "        [1.6952099e-05],\n",
       "        [1.7990903e-03],\n",
       "        [1.4925064e-03],\n",
       "        [4.3216706e-04],\n",
       "        [9.9475241e-01],\n",
       "        [3.1526511e-06],\n",
       "        [7.9765567e-07],\n",
       "        [1.5405336e-04],\n",
       "        [3.5752100e-04]], dtype=float32)>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.98300296]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(11, 1), dtype=float32, numpy=\n",
       " array([[1.4789340e-04],\n",
       "        [1.0431281e-03],\n",
       "        [1.3995325e-04],\n",
       "        [8.4589956e-06],\n",
       "        [9.4913272e-04],\n",
       "        [7.3591148e-04],\n",
       "        [2.6245814e-04],\n",
       "        [9.9467802e-01],\n",
       "        [1.8532244e-05],\n",
       "        [1.0638222e-03],\n",
       "        [9.5277268e-04]], dtype=float32)>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[5][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = [i[0] for i in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_y = [i[2] for i in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_set_x = np.concatenate(train_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_set_y = np.concatenate(train_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x.npy', train_data_set_x)\n",
    "np.save('y.npy', train_data_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.feature_extract.save('feature_extract.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1e39bb509cfb5ccd31f70cb06d48c419b771ae25efbac49dcd3f7bd695e8586"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
